# Awesome Personalized Large Language Model
This repository collects the latest research progress on personalized large language models (LLMs), including preference alignment and user-customized generation. Comments and contributions are welcome.

> The contributions are expected to be submitted as follows:
> 
> `+ \[Year Conference/Jounal\] Title. ([paper](link), [code](link) (if accessible))`.

## Preference Alignment



### Survey/Tutorial/Framework



### Benchmark/Dataset

\[2024 NeurIPS\] The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models. ([paper](https://arxiv.org/pdf/2404.16019), [code](https://hannahkirk.github.io/prism-alignment/))

### SFT/RLHF/DPO-based Methods

### Traning-free Methods

## User-customized Generation

### Survey/Tutorial/Framework

+ \[2024 EMNLP\] Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization. ([paper](https://arxiv.org/pdf/2406.01171), [code](https://github.com/MiuLab/PersonaLLM-Survey))

  

### Benchmark/Dataset

+ \[2024 ACL\] LaMP: When Large Language Models Meet Personalization. ([paper](https://aclanthology.org/2024.acl-long.399.pdf), [code](https://lamp-benchmark.github.io/))

+ \[2024 Arxiv-2407\] LongLaMP: A Benchmark for Personalized Long-form Text Generation. ([paper](https://arxiv.org/pdf/2407.11016), [code](https://longlamp-benchmark.github.io/papers))

+ \[2024 NeurIPS\] PersonalSum: A User-Subjective Guided Personalized Summarization Dataset for Large Language Models. ([paper](https://arxiv.org/pdf/2410.03905), [code](https://github.com/SmartmediaAI/PersonalSum))


### Retrieval-Augmented Generation / Profile-Augmented Generation (RAG/PAG)-based Methods

+ \[2024 SIGIR\] Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation. ([paper](https://dlnext.acm.org/doi/pdf/10.1145/3626772.3657783), [code](https://dlnext.acm.org/doi/pdf/10.1145/3626772.3657783)

+ \[2023 CIKM\] Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models ([paper](https://arxiv.org/pdf/2310.20081))


### Parameter-Efficient-Fine-Tuning (PEFT)-based Methods

+ \[2024 Arxiv-2409\] LLMs + Persona-Plug = Personalized LLMs. ([paper](https://arxiv.org/pdf/2409.11901))

+ \[2024 EMNLP\] Can LLM be a Personalized Judge? ([paper]([link](https://arxiv.org/pdf/2406.11657)), [code]([link](https://github.com/dong-river/Personalized-Judge)))

+ \[2024 EMNLP\] Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning. ([paper](https://arxiv.org/pdf/2402.04401), [code](https://github.com/TamSiuhin/OPPU))
 
+ \[2024 EMNLP\] Guided Profile Generation Improves Personalization with LLMs. ([paper](https://arxiv.org/pdf/2409.13093))

+ \[2024 EMNLP\] HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs. ([paper](https://arxiv.org/pdf/2405.17633), [code](https://github.com/mitmedialab/heartfelt-narratives-emnlp))

+ \[2024 EMNLP\] Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts. ([paper](https://arxiv.org/pdf/2406.10471), [code](https://github.com/TamSiuhin/Per-Pcs))

+ \[2024 NeurIPS\] HYDRA: Model Factorization Framework for Black-Box LLM Personalization. ([paper](https://arxiv.org/pdf/2406.02888v1), [code](https://arxiv.org/pdf/2406.02888v1))



