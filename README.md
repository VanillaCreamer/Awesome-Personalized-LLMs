# Awesome Personalized Large Language Models
This repository collects the latest research progress on personalized large language models (LLMs), including preference alignment and user-customized generation. Comments and contributions are welcome.

> The contributions are expected to be submitted as follows:
> 
> `+ \[Year Conference/Jounal\] Title. ([paper](link), [code](link))`  (if accessible).

+ \[2024 Arxiv-2411\] Personalization of Large Language Models: A Survey. ([paper](https://arxiv.org/pdf/2411.00027))

## 1. Preference Alignment

### 1.1 Survey/Tutorial/Framework


### 1.2 Benchmark/Dataset

+ \[2024 NeurIPS\] The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models. ([paper](https://arxiv.org/pdf/2404.16019), [code](https://hannahkirk.github.io/prism-alignment/))

+ \[2024 GitHub\] Personalized LMs: Aligning Language Models with Diverse Human Preference. ([Link](https://github.com/allenai/compred))

+ \[2024 Arxiv-2408\]Personality Alignment of Large Language Models. ([paper](https://arxiv.org/pdf/2408.11779), [code](https://github.com/zhu-minjun/PAlign))

### 1.3 SFT/RLHF/DPO-based Methods

+ \[2024 Arxiv-2410\] COMPO: Community Preferences for Language Model Personalization. ([paper](https://arxiv.org/pdf/2410.16027))

+ \[2024 Arxiv-2402\] Personalized Language Modeling from Personalized Human Feedback. ([paper](https://openreview.net/pdf?id=bqUsdBeRjQ))

+ \[2024 ACL\] Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards. ([paper](https://aclanthology.org/2024.acl-long.468.pdf), [code](https://github.com/RLHFlow/Directional-Preference-Alignment))

+ \[2024 EMNLP\] On Diversified Preferences of Large Language Model Alignment. ([paper](https://arxiv.org/pdf/2312.07401), [code](https://github.com/dunzeng/MORE))

+ \[2024 NeurIPS\] Panacea: Pareto Alignment via Preference Adaptation for LLMs. ([paper](https://arxiv.org/pdf/2402.02030))

+ \[2023 NeurIPS\] Rewarded soups: towards Pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards. ([paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/e12a3b98b67e8395f639fde4c2b03168-Paper-Conference.pdf), [code](https://github.com/alexrame/rewardedsoups))




### 1.4 Traning-free Methods

+ \[2024 Arxiv-2410\] Neuron-based Personality Trait Induction in Large Language Models. ([paper](https://arxiv.org/pdf/2410.12327), [code](https://github.com/RUCAIBox/NPTI))

+ \[2024 ICLR Workshop\] Prompt Optimization with Logged Bandit Data. ([paper](https://openreview.net/pdf?id=Byj8MMJmoL))

+ \[2024 NeurIPS\] Decoding-Time Language Model Alignment with Multiple Objectives. ([paper](https://openreview.net/pdf?id=RmGvEmttB7))



## 2 User-customized Generation

### 2.1 Survey/Tutorial/Framework

+ \[2024 EMNLP\] Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization. ([paper](https://arxiv.org/pdf/2406.01171), [code](https://github.com/MiuLab/PersonaLLM-Survey))

  

### 2.2 Benchmark/Dataset

+ \[2024 WI-IAT\] Synthetic Data Generation with Large Language Models for Personalized Community Question Answering. ([paper](https://arxiv.org/pdf/2410.22182))

+ \[2024 Arxiv-2410\] Large Language Models Empowered Personalized Web Agents. ([paper](https://arxiv.org/pdf/2410.17236), [code](https://hongrucai.github.io/PersonalWAB/))

+ \[2024 Arxiv-2407\] LongLaMP: A Benchmark for Personalized Long-form Text Generation. ([paper](https://arxiv.org/pdf/2407.11016), [code](https://longlamp-benchmark.github.io/papers))

+ \[2024 Arxiv-2406\] STEP-BACK PROFILING: Distilling User History for Personalized Scientific Writing. ([paper](https://arxiv.org/pdf/2406.14275), [code](https://github.com/gersteinlab/step-back-profiling))

+ \[2024 ACL\] LaMP: When Large Language Models Meet Personalization. ([paper](https://aclanthology.org/2024.acl-long.399.pdf), [code](https://lamp-benchmark.github.io/))

+ \[2024 NeurIPS\] PersonalSum: A User-Subjective Guided Personalized Summarization Dataset for Large Language Models. ([paper](https://arxiv.org/pdf/2410.03905), [code](https://github.com/SmartmediaAI/PersonalSum))

+ \[2024 PERSONALIZE\]Personalized Text Generation with Fine-Grained Linguistic Control. ([paper](https://aclanthology.org/2024.personalize-1.8.pdf), [code](https://github.com/balhafni/personalized-gen))


### 2.3 Retrieval-Augmented Generation / Profile-Augmented Generation (RAG/PAG)-based Methods

+ \[2024 Arxiv-2411\] PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation. ([paper](https://arxiv.org/pdf/2411.13902))

+ \[2024 Arxiv-2411\] Orca: Enhancing Role-Playing Abilities of Large Language Models by Integrating Personality Traits. ([paper](https://arxiv.org/pdf/2411.10006)) 

+ \[2024 Arxiv-2411\] The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses. ([paper](https://arxiv.org/pdf/2411.06008))

+ \[2024 Arxiv-2410\] Using Prompts to Guide Large Language Models in Imitating a Real Person's Language Style. ([paper](https://arxiv.org/pdf/2410.03848))

+ \[2024 Arxiv-2404\] Dynamic Generation of Personalities with Large Language Models. ([paper](https://arxiv.org/pdf/2404.07084v1), )

+ \[2023 CIKM\] Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models. ([paper](https://arxiv.org/pdf/2310.20081))

+ \[2024 EMNLP\] Guided Profile Generation Improves Personalization with LLMs. ([paper](https://arxiv.org/pdf/2409.13093))

+ \[2024 SIGIR\] Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation. ([paper](https://dlnext.acm.org/doi/pdf/10.1145/3626772.3657783), [code](https://dlnext.acm.org/doi/pdf/10.1145/3626772.3657783))


### 2.4 Parameter-Efficient-Fine-Tuning (PEFT)-based Methods

+ \[2024 Arxiv-2410\] PAD: Personalized Alignment of LLMs at Decoding-Time. ([paper](https://arxiv.org/pdf/2410.04070))

+ \[2024 Arxiv-2410\] LMLPA: Language Model Linguistic Personality Assessment. ([paper](https://arxiv.org/pdf/2410.17632))

+ \[2024 Arxiv-2409\] LLMs + Persona-Plug = Personalized LLMs. ([paper](https://arxiv.org/pdf/2409.11901))

+ \[2024 Arxiv-2408\] StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements. ([paper](https://arxiv.org/pdf/2408.15666), [code](https://github.com/jfisher52/StyleRemix))

+ \[2024 Arxiv-2406\] P-Tailor: Customizing Personality Traits for Language Models via Mixture of Specialized LoRA Experts. ([paper](https://arxiv.org/pdf/2406.12548v1))

+ \[2024 Arxiv-2404\] Online Personalizing White-box LLMs Generation with Neural Bandits. ([paper](https://arxiv.org/pdf/2404.16115))

+ \[2024 EMNLP\] Can LLM be a Personalized Judge? ([paper]([link](https://arxiv.org/pdf/2406.11657)), [code]([link](https://github.com/dong-river/Personalized-Judge)))

+ \[2024 EMNLP\] Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning. ([paper](https://arxiv.org/pdf/2402.04401), [code](https://github.com/TamSiuhin/OPPU))
 
+ \[2024 EMNLP\] Guided Profile Generation Improves Personalization with LLMs. ([paper](https://arxiv.org/pdf/2409.13093))

+ \[2024 EMNLP\] HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs. ([paper](https://arxiv.org/pdf/2405.17633), [code](https://github.com/mitmedialab/heartfelt-narratives-emnlp))

+ \[2024 EMNLP\] Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts. ([paper](https://arxiv.org/pdf/2406.10471), [code](https://github.com/TamSiuhin/Per-Pcs))

+ \[2024 NeurIPS\] HYDRA: Model Factorization Framework for Black-Box LLM Personalization. ([paper](https://arxiv.org/pdf/2406.02888v1), [code](https://arxiv.org/pdf/2406.02888v1))




